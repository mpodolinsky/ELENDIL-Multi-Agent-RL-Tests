# heterogeneous-marl
Heterogeneous multi-agent teaming using multi-agent RL (MARL)

# North Star
Improve the (stability, reliability, speed) of heterogeneous multi-agent reinforcement learning.
--> What is the quantity we are optimizing? What do we bring that is new?
--> It feels like this is very much just a communication problem but I an not sure this is necessarely our goal. Since here the Agent B basically fully controls the agent A.
--> I feel like we need an additional complication to make this problem interesting?
--> Idea of something adversarial? (Ufuk talked about for example about information vs risk of noticing)